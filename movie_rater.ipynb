{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPs+tXhLSFDAg7gWSc2fP7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sioulruble/movie_rater_IMDB/blob/main/movie_rater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Movie Rater project using differents deep learning architectures"
      ],
      "metadata": {
        "id": "uAJSbbvJR9GK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Preprocessing"
      ],
      "metadata": {
        "id": "VavfmfcYSJ7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX1Gs1flNAqj",
        "outputId": "1bfb9c23-3648-474b-e86a-01b78a814240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de données : 50000\n",
            "Nombre de critiques positives : 25000\n",
            "Nombre de critiques négatives : 25000\n",
            "(40000,) (10000,) (40000,) (10000,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('IMDB_Dataset.csv')\n",
        "\n",
        "print(f\"Nombre total de données : {len(df)}\")\n",
        "\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "print(f\"Nombre de critiques positives : {sentiment_counts['positive']}\")\n",
        "print(f\"Nombre de critiques négatives : {sentiment_counts['negative']}\")\n",
        "x = df['review']\n",
        "y = df['sentiment'].map({'positive': 0, 'negative': 1})\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Tokenizer"
      ],
      "metadata": {
        "id": "KPdoldduSOMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "x = 'Salut ! Comment ca va chef ?'\n",
        "print(\"tokenization\", tokenizer(x)['input_ids'])\n",
        "print(\"5 tokens max per sequence\",tokenizer(x, truncation=True, max_length=5)['input_ids'])\n",
        "print(\"15 tokens max per sequence\",tokenizer(x, padding='max_length', truncation=True, max_length=15)['input_ids'])\n",
        "\n",
        "#tokenize the training and test dataset\n",
        "max_len=100\n",
        "x_train_tokenized = [ tokenizer(x, padding='max_length', truncation=True, max_length=max_len)['input_ids'] for x in x_train ]\n",
        "x_test_tokenized = [ tokenizer(x, padding='max_length', truncation=True, max_length=max_len)['input_ids'] for x in x_test ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYljLbcjN7OO",
        "outputId": "e8b7fd2f-9e13-42ab-f7bd-e1f20abad3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenization [19221, 315, 5145, 18957, 1275, 46935, 21221, 5633]\n",
            "5 tokens max per sequence [19221, 315, 5145, 18957, 1275]\n",
            "15 tokens max per sequence [19221, 315, 5145, 18957, 1275, 46935, 21221, 5633, 50256, 50256, 50256, 50256, 50256, 50256, 50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "trainset = torch.utils.data.TensorDataset(torch.tensor(x_train_tokenized), torch.tensor(np.array(y_train, dtype=np.int64)))\n",
        "x, y = trainset[0]\n",
        "print(x, y)\n",
        "print( tokenizer.decode(x) )\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32)\n",
        "\n",
        "print( len( tokenizer ))\n",
        "print( tokenizer.vocab_size )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky4rEMULZUOG",
        "outputId": "88113049-be1b-4341-fa36-eb36e84a7b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2504,   338,   644,   314,  4030,  4737,  3589,  1141,   262,   867,\n",
            "        11418,    11, 14788,  7466,    11, 38372,   290,  2276, 43744,   326,\n",
            "        29298,   378,   262,  9508,  2431,    13,   383, 17909,   635,  1302,\n",
            "          510,   618,   345,   892,   286,   262,   530,    12, 19577,  3435,\n",
            "           11,   508,   423,   523,  1310,  6795,   326,   340,   318,  9826,\n",
            "         5340,   284,  1337,   644,  4325,   284,   606,    13,  1119,   389,\n",
            "          655, 11234,  3194,  3075,    79,  7084,   329,   262,  3437,   284,\n",
            "         8181,   465, 34641,  9056,   319,    11,   257,  7243,   326,   468,\n",
            "          587,  1760,   881,  1365,   287,   584, 43972,  1111,   319,  3195,\n",
            "          290,   262, 22041, 29847,  1671,  1220,  6927,  1671, 11037,    40]) tensor(1)\n",
            "That's what I kept asking myself during the many fights, screaming matches, swearing and general mayhem that permeate the 84 minutes. The comparisons also stand up when you think of the one-dimensional characters, who have so little depth that it is virtually impossible to care what happens to them. They are just badly written cyphers for the director to hang his multicultural beliefs on, a topic that has been done much better in other dramas both on TV and the cinema.<br /><br />I\n",
            "50257\n",
            "50257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb1 = torch.nn.Embedding(50257, 128)\n",
        "emb_example = torch.nn.Embedding(50257, 300)\n",
        "lstm_example = torch.nn.LSTM(300, 100, batch_first=True, bidirectional=False)\n",
        "x = torch.randint(0, 50257, (32, 100))\n",
        "print(x.shape, x.dtype)\n",
        "x, state = lstm_example(emb_example(x))\n",
        "print( x.shape, state[0].shape, state[1].shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVlidNWJckC0",
        "outputId": "f4b59e8b-fd70-429e-d563-d9477d36f9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 100]) torch.int64\n",
            "torch.Size([32, 100, 100]) torch.Size([1, 32, 100]) torch.Size([1, 32, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM-based Sequence Classification Model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "po16w-Rpfj41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "class Net1(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embedding = torch.nn.Embedding(50257, 128)\n",
        "    self.LSTM = torch.nn.LSTM(128, 128, batch_first=True, bidirectional=False, num_layers=1)\n",
        "    self.drop = torch.nn.Dropout(0.5)\n",
        "    self.linear1 = torch.nn.Linear(128, 2)\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x, _ = self.LSTM(x)\n",
        "    x = torch.mean(x, dim=1)\n",
        "    x = self.drop(x)\n",
        "    x = self.linear1(x)\n",
        "    return x\n",
        "  def predict(self, x):\n",
        "    with torch.no_grad():\n",
        "      x = self.forward(x)\n",
        "      return torch.argmax(x, dim=1)\n",
        "\n",
        "  def predict_proba(self, x):\n",
        "    with torch.no_grad():\n",
        "      x = self.forward(x)\n",
        "      return torch.softmax(x, dim=1)\n",
        "\n",
        "  # Instantiate the model\n",
        "model = Net1().cuda()\n"
      ],
      "metadata": {
        "id": "TU_DG8Fifpyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(tqdm(trainloader)):\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(trainloader)}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"movie_rater_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBxXIi5Nilwa",
        "outputId": "a69c7ef5-6971-45fe-f930-f7a090145a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:13<00:00, 89.61it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.5088964509606362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:05<00:00, 214.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Loss: 0.33413186519145965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:06<00:00, 194.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Loss: 0.2360781230777502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:05<00:00, 213.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Loss: 0.14568036005795001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:06<00:00, 195.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Loss: 0.08437187575995922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:05<00:00, 213.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Loss: 0.058915777200507\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:06<00:00, 193.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Loss: 0.044435661974782124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:05<00:00, 213.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Loss: 0.024284927038384193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:06<00:00, 195.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Loss: 0.01627169949197978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [00:05<00:00, 214.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Loss: 0.011200788322390872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "text = 'The movie was horrible!, the worst movie I have seen'\n",
        "x = tokenizer(text, padding='max_length', truncation=True, max_length=max_len)['input_ids']\n",
        "x = torch.tensor(x).unsqueeze(0).to(device)\n",
        "print(model.predict_proba(x))\n",
        "text = 'The movie was incredible!, the best movie I have seen'\n",
        "x = tokenizer(text, padding='max_length', truncation=True, max_length=max_len)['input_ids']\n",
        "x = torch.tensor(x).unsqueeze(0).to(device)\n",
        "print(model.predict_proba(x))\n",
        "text = 'The movie was very good'\n",
        "x = tokenizer(text, padding='max_length', truncation=True, max_length=max_len)['input_ids']\n",
        "x = torch.tensor(x).unsqueeze(0).to(device)\n",
        "print(model.predict_proba(x))\n",
        "text = 'The movie was not very good'\n",
        "x = tokenizer(text, padding='max_length', truncation=True, max_length=max_len)['input_ids']\n",
        "x = torch.tensor(x).unsqueeze(0).to(device)\n",
        "print(model.predict_proba(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-WITYfPmhiW",
        "outputId": "486bb5dc-fb34-4ce1-be4d-c5cedee4d0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0786e-20, 1.0000e+00]], device='cuda:0')\n",
            "tensor([[9.9999e-01, 7.3054e-06]], device='cuda:0')\n",
            "tensor([[0.0111, 0.9889]], device='cuda:0')\n",
            "tensor([[5.1797e-04, 9.9948e-01]], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}